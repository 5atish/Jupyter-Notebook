{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Vectors and Vector Arithmetic\n",
    "\n",
    "We can represent a vector in Python as a NumPy array. \n",
    "\n",
    "7.4 Vector Arithmetic\n",
    "7.4.1 Vector Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "[18 21 24]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "a = array([1, 2, 3])\n",
    "b = array([6, 7, 8])\n",
    "# print(a+b) #Addition\n",
    "# print(b-a) #Subtraction\n",
    "# print(a*b) #Multiplication\n",
    "# print(b/a) # Division\n",
    "print(a.dot(b)) #Calculate the sum of the multiplied elements of two vectors of the same length \n",
    "                #to give scalar, callded dot Product.\n",
    "print(b*3) #Vector-Scalar Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Vector Norms\n",
    "\n",
    "Calculating the size or length of a vector is often required either directly or as part of a broader vector or vector-matrix operation. The length of the vector is referred to as the vector norm or the vector's magnitude.\n",
    "\n",
    "8.3 Vector L^1 Norm\n",
    "The length of a vector can be calculated using the L^1 norm, where the 1 is a superscript of the L. The L^1 norm is calculated as the sum of the absolute vector values, where the absolute value of a scalar uses the notation |a|\n",
    "\n",
    "8.4 Vector L^2 Norm\n",
    "The length of a vector can be calculated using the L^2 norm, where the 2 is a superscript of the L. The L^2 norm calculates the distance of the vector coordinate from the origin of the vector space. As such, it is also known as the Euclidean norm as it is calculated as the Euclidean distance from the origin. \n",
    "\n",
    "L^1 and L^2 norm is often used when fitting machine learning algorithms as a regularization method, e.g. a method to keep the coefficients of the model small and, in turn, the model less complex.\n",
    "\n",
    "8.5 Vector Max Norm\n",
    "\n",
    "The length of a vector can be calculated using the maximum norm, also called max norm. Max norm of a vector is referred to as L^inf where inf is a superscript.The max norm of a vector can be calculated in NumPy using the norm() function with the order parameter set to infinity. Max norm is also used as a regularization in machine learning, such as on neural network weights, called max norm regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "3.7416573867739413\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy.linalg import norm # L^1 and L^2 norm of a vector can be calculated in NumPy using the norm() function \n",
    "from math import inf # import infinity\n",
    "a = array([1, 2, 3]) \n",
    "print(norm(a,1)) # L^1 norm, calculate the sum of the absolute vector values\n",
    "print(norm(a)) #L^2 norm,  calculates the distance of the vector coordinate from the origin of\n",
    "               # the vector space.\n",
    "print(norm(a, inf)) #max (L^inf) norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Matrices and Matrix Arithmetic\n",
    "\n",
    "A matrix is a two-dimensional array of scalars with one or more columns and one or more rows and entries are referred to by their two-dimensional subscript of row (i) and column (j) For example, we can de\f",
    "ne a 3-row, 2-column matrix as\n",
    "            A = ((a1.1; a1.2); (a2.1; a2.2); (a3.1; a3.2)) \n",
    "            \n",
    "9.3 Defining a Matrix\n",
    "9.4 Matrix Arithmetic\n",
    "9.4.1 Matrix Addition\n",
    "Matrix Subtraction\n",
    "Matrix Multiplication \n",
    "Matrix Division\n",
    "Matrix-Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42 99]\n",
      "[ 82 147 110]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "A = array([[1, 2, 3], [4, 5, 6]])  #Defining a Matrix\n",
    "#print(A)\n",
    "\n",
    "B = array([[2, 3, 7], [4, 8, 9]])\n",
    "C = array([[2, 3, 7], [4, 8, 9], [3, 5, 8]])\n",
    "D = array([3,9,7])\n",
    "#print(A+B) # Matrix Addition\n",
    "#print(B-A) #Matrix Subtraction\n",
    "#print(B*A) #Matrix Multiplication \n",
    "#print(B/A) #Matrix Division\n",
    "print(A.dot(D)) #Matrix-Matrix Multiplication\n",
    "#print(C)\n",
    "#print(D)\n",
    "print(C.dot(D)) #Matrix-Vector Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Types of Matrices\n",
    "\n",
    "10.2 Square Matrix -  \n",
    "A square matrix is a matrix where the number of rows (n) is equivalent to the number of columns (m). e.g. n = m \n",
    "\n",
    "10.3 Symmetric Matrix\n",
    "A symmetric matrix is a type of square matrix where the top-right triangle is the same as the bottom-left triangle.\n",
    "\n",
    "            1 2 3 \n",
    "     m =    2 1 2 \n",
    "            3 2 1 \n",
    "            \n",
    "10.4 Triangular Matrix\n",
    "A triangular matrix is a type of square matrix that has all values in the upper-right or lower-left of the matrix with the remaining elements filled with zero values. \n",
    "\n",
    "                   1 2 3           1 0 0\n",
    "              m =  0 2 3           1 2 0\n",
    "                   0 0 3           1 2 3 \n",
    "\n",
    "10.5 Diagonal Matrix\n",
    "A diagonal matrix is one where values outside of the main diagonal have a zero value, where the main diagonal is taken from the top left of the matrix to the bottom right.\n",
    "\n",
    "         1 0 0\n",
    "    D  = 0 2 0\n",
    "         0 0 3\n",
    "         \n",
    "10.6 Identity Matrix\n",
    "An identity matrix is a square matrix that does not change a vector when multiplied. All of the scalar values along the main diagonal (top-left to bottom-right) have the value one, while all other values are zero.\n",
    "\n",
    "                1 0 0\n",
    "            I = 0 1 0\n",
    "                0 0 1\n",
    "\n",
    "10.7 Orthogonal Matrix\n",
    "Two vectors are orthogonal when their dot product equals zero. The length of each vector is 1 then the vectors are called orthonormal because they are both orthogonal and normalized\n",
    "\n",
    "'v \u0001 w = 0'  OR 'v \u0001 w^T= 0' \n",
    "\n",
    "This is intuitive when we consider that one line is orthogonal with another if it is perpendicular to it. An orthogonal matrix is a type of square matrix whose columns and rows are orthonormal unit vectors, e.g. perpendicular and have a length or magnitude of 1.\n",
    "\n",
    "An Orthogonal matrix is often denoted as uppercase Q and defined formally as follows:\n",
    "\n",
    "Q \u0001 Q^T = Q^T \u0001 Q = I "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.]\n",
      " [-0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import tril\n",
    "from numpy import triu\n",
    "from numpy import diag\n",
    "from numpy import identity\n",
    "from numpy.linalg import inv\n",
    "\n",
    "M = array([[2, 3, 7], [4, 8, 9], [3, 5, 8]])\n",
    "#print(tril(M)) #lower triangular matrix\n",
    "#print(triu(M)) #upper triangular matrix\n",
    "#print(diag(M)) #extract diagonal vector\n",
    "#print(diag(diag(M))) #create diagonal matrix from vector\n",
    "#print(identity(3)) #Identity Matrix\n",
    "\n",
    "Q = array([[1, 0], [0, -1]]) #orthogonal matrix, Two vectors are orthogonal when their dot \n",
    "                             #product equals zero\n",
    "V = inv(Q) # inverse matrix of Q\n",
    "print(Q*V)\n",
    "# print(Q)\n",
    "# print(V)\n",
    "# print(Q.T) # transpose of matrix T\n",
    "# print(Q.dot(Q.T)) #identity matrix, calculated from the dot product of the orthogonal \n",
    "                  #matrix with its transpose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Matrix Operations\n",
    "\n",
    "Matrix operations are used in the description of many machine learning algorithms. Some operations can be used directly to solve key equations, whereas others provide useful shorthand or foundation in the description and the use of more complex matrix operations. \n",
    "\n",
    "11.2 Transpose\n",
    "\n",
    "A defined matrix can be transposed, which creates a new matrix with the number of columns\n",
    "and rows flipped. This is denoted by the superscript T next to the matrix A^T.\n",
    "\n",
    "         C = A^T            1 2\n",
    "                        A = 3 4             A^T = 1 3 5\n",
    "                            5 6                   2 4 6\n",
    "                            \n",
    "\n",
    "11.3 Inverse\n",
    "\n",
    "Matrix inversion is a process that finds another matrix that when multiplied with the matrix,\n",
    "results in an identity matrix. Given a matrix A, find matrix B, such that AB= I^n  or BA = I^n.\n",
    "\n",
    "        AB= BA = I^n\n",
    "\n",
    "The operation of inverting a matrix is indicated by a -1 superscript next to the matrix; for example, A^-1. The result of the operation is referred to as the inverse of the original matrix; for example, B is the inverse of A. B = A^-1\n",
    "\n",
    "11.4 Trace\n",
    "\n",
    "A trace of a square matrix is the sum of the values on the main diagonal of the matrix (top-left to bottom-right). The operation of calculating a trace on a square matrix is described using the notation tr(A) where A is the square matrix on which the operation is being performed.\n",
    "\n",
    "11.5 Determinant\n",
    "\n",
    "The determinant describes the relative geometry of the vectors that make up the rows of the matrix. More specifically, the determinant of a matrix A tells you the volume of a box with sides given by rows of A. It is denoted by the det(A) notation. \n",
    "\n",
    "11.6 Rank\n",
    "\n",
    "The rank of a matrix is the estimate of the number of linearly independent rows or columns in a matrix. The rank of a matrix M is often denoted as the function rank(). NumPy provides the matrix rank() function for calculating the rank of an array. It uses Singular-ValueDecomposition or the SVD method to estimate the rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "-9.51619735392994e-16\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import trace\n",
    "from numpy.linalg import det\n",
    "from numpy.linalg import matrix_rank\n",
    "\n",
    "A = array([\n",
    "[1, 2],\n",
    "[3, 4],\n",
    "[5, 6]])\n",
    "#print(A.T) #calculate transpose of A\n",
    "\n",
    "A = array([\n",
    "[1, 2],\n",
    "[3, 4],])\n",
    "#print(inv(A)) #invert matrix of A\n",
    "# print(A.dot(inv(A))) #multiply A and invert of A\n",
    "\n",
    "A = array([\n",
    "[1, 2, 3],\n",
    "[4, 5, 6],\n",
    "[7, 8, 9]])\n",
    "print(trace(A)) #calculate trace of A, sum of the values on the main diagonal of the matrix\n",
    "print(det(A)) #calculate determinant of A, the volume of a box with sides given by rows of A\n",
    "print(matrix_rank(A)) #the estimate of the number of linearly independent rows or columns in \n",
    "                      # a matrix. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 12. Sparse Matrices\n",
    "\n",
    "Matrices that contain mostly zero values are called sparse, distinct from matrices where most of the values are non-zero, called dense. \n",
    "\n",
    "12.2 Sparse Matrix\n",
    "\n",
    "A sparse matrix is a matrix that is comprised of mostly zero values. The sparsity of a matrix can be quantified with a score, which is the number of zero values the matrix divided by the total number of elements in the matrix.\n",
    "\n",
    "                    sparsity = (count of non-zero elements / total elements)\n",
    "                    \n",
    "                    A = 1 0 0 1 0 0\n",
    "                        0 0 2 0 0 1\n",
    "                        0 0 0 2 0 0\n",
    "\n",
    "The example has 13 zero values of the 18 elements in the matrix, giving this matrix a sparsity score of 0.722 or about 72%.\n",
    "\n",
    "12.3 Problems with Sparsity\n",
    "\n",
    "    12.3.1 Space Complexity\n",
    "    \n",
    "  Very large matrices require a lot of memory, and some very large matrices that we wish to work with are sparse. sparse matrix contained more zero values than data values. problem with representing these sparse matrices is that memory is required and must be allocated for each 32-bit or even 64-bit zero value in the matrix. This is clearly a waste of memory resources as those zero values do not contain any information.\n",
    "\n",
    "    12.3.2 Time Complexity\n",
    "   \n",
    "  Assuming a very large sparse matrix can be fit into memory, we will want to perform operations on this matrix. If the matrix contains mostly zero-values, i.e. no data, then performing operations across this matrix may take a long time where the bulk of the computation performed will involve adding or multiplying zero values together. This is a problem of increased time complexity of matrix operations that increases with the size of the matrix. \n",
    "  \n",
    "\n",
    "12.4 Sparse Matrices in Machine Learning\n",
    "\n",
    "    12.4.1 Data\n",
    "    \n",
    "   Sparse matrices come up in some specific types of data, most notably observations that record the occurrence or count of an activity.\n",
    "   e.g. Whether or not a user has watched a movie in a movie catalog \n",
    "        or Count of the number of listens of a song in a song catalog.\n",
    "    \n",
    "    12.4.2 Data Preparation\n",
    "   \n",
    "  parse matrices come up in encoding schemes used in the preparation of data. e.g.\n",
    "  1) One hot encoding, used to represent categorical data as sparse binary vectors.\n",
    "  2) Count encoding, used to represent the frequency of words in a vocabulary for a document\n",
    "  3) TF-IDF encoding, used to represent normalized word frequency scores in a vocabulary.\n",
    "  \n",
    "    12.4.3 Areas of Study\n",
    "  \n",
    "  areas of study within machine learning must develop specialized methods to address sparsity directly as the input data is almost always sparse. e.g.\n",
    "  1) Natural language processing for working with documents of text\n",
    "  2) Recommender systems for working with product usage within a catalog.\n",
    "  3) Computer vision when working with images that contain lots of black pixels.\n",
    "  \n",
    "12.5 Working with Sparse Matrices\n",
    "\n",
    "The solution to representing and working with sparse matrices is to use an alternate data structure to represent the sparse data. The zero values can be ignored and only the data or non-zero values in the sparse matrix need to be stored or acted upon. There are multiple data structures that can be used to efficiently construct a sparse matrix. e.g.\n",
    "   \n",
    "   1) Dictionary of Keys - A dictionary is used where a row and column index is mapped to a value\n",
    "   2) List of Lists - Each row of the matrix is stored as a list, with each sublist containing the column index and the value.\n",
    "   3) Coordinate List - A list of tuples is stored with each tuple containing the row index, column index, and the value.\n",
    "   \n",
    "There are also data structures that are more suitable for performing efficient operations.\n",
    "\n",
    "   1) Compressed Sparse Row - The sparse matrix is represented using three one-dimensional arrays for the non-zero values, the extents of the rows, and the column indexes. It lso called CSR for short, is often used to represent sparse matrices in machine learning given the efficient access and matrix multiplication that it supports.\n",
    "\n",
    "   2) Compressed Sparse Column - The same as the Compressed Sparse Row method except the column indices are compressed and read first before the row indices.\n",
    "\n",
    "12.6 Sparse Matrices in Python\n",
    "\n",
    "SciPy provides tools for creating sparse matrices using multiple data structures, as well as tools for converting a dense matrix to a sparse matrix. Many linear algebra NumPy and SciPy functions that operate on NumPy arrays can transparently operate on SciPy sparse arrays. machine learning libraries that use NumPy data structures can also operate transparently on SciPy sparse arrays, such as scikit-learn for general machine learning and Keras for deep learning.\n",
    "\n",
    "A dense matrix stored in a NumPy array can be converted into a sparse matrix using the CSR representation by calling the csr_matrix() function. In the example below, we define a 3\u00026 sparse matrix as a dense array (e.g. an ndarray), convert it to a CSR sparse representation, and then convert it back to a dense array by calling the todense() function.\n",
    "\n",
    "NumPy does not provide a function to calculate the sparsity of a matrix. Nevertheless, we can calculate it easily by first finding the density of the matrix and subtracting it from one. The number of non-zero elements in a NumPy array can be given by the count nonzero() function and the total number of elements in the array can be given by the size property of the array. Array sparsity can therefore be calculated as\n",
    "\n",
    "                sparsity = 1.0 - count_nonzero(A) / A.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "18\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from numpy import array \n",
    "from numpy import count_nonzero\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "A = array([\n",
    "[1, 0, 0, 1, 0, 0],\n",
    "[0, 0, 2, 0, 0, 1],\n",
    "[0, 0, 0, 2, 0, 0]])\n",
    "\n",
    "S = csr_matrix(A) #convert to sparse matrix (CSR method)\n",
    "#print(S)\n",
    "B = S.todense() #reconstruct dense matrix\n",
    "#print(B) \n",
    "print(count_nonzero(A)) # Count Non zeros in Matrix A \n",
    "print(A.size) # Total element in Matrix A\n",
    "sparsity = 1.0 - count_nonzero(A) / A.size #calculate sparsity of Matrix A\n",
    "print(sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Tensors and Tensor Arithmetic\n",
    "\n",
    "13.2 What are Tensors\n",
    "\n",
    "A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array. i.e. an array of numbers arranged on a regular grid with a variable number of axes is known as a tensor.A vector is a one-dimensional or first order tensor and a matrix is a two-dimensional or second order tensor. \n",
    "Tensor notation is much like matrix notation with a capital letter representing a tensor and lowercase letters with subscript integers representing scalar values within the tensor. For example, below defines a 3 * 3 * 3 three-dimensional tensor T with dimensions index as t(i;j;k).\n",
    "\n",
    "    t(1;1;1) t(1;2;1) t(1;3;1)       t(1;1;2) t(1;2;2) t(1;3;3)      t(1;1;3) t(1;2;3) t(1;3;3)\n",
    "T = t(2;1;1) t(2;2;1) t(2;3;1)   ,   t(2;1;2) t(2;2;2) t(2;3;3)   ,  t(2;1;3) t(2;2;3) t(2;3;3)\n",
    "    t(3;1;1) t(3;2;1) t(3;3;1)       t(3;1;2) t(3;2;2) t(3;3;3)      t(3;1;3) t(3;2;3) t(3;3;3)\n",
    "                \n",
    "\n",
    "13.3 Tensors in Python\n",
    "\n",
    "Tensors can be represented in Python using the N-dimensional array(ndarray). A tensor can be defined in-line to the constructor of array() as a list of lists. The example below defines a 3 * 3 * 3 tensor as a NumPy ndarray. Here, we first define rows, then a list of rows stacked as columns, then a list of columns stacked as levels in a cube\n",
    "\n",
    "13.4 Tensor Arithmetic\n",
    "\n",
    "As with matrices, we can perform element-wise arithmetic between tensors\n",
    "\n",
    "    13.4.1 Tensor Addition\n",
    "    \n",
    "  The element-wise addition of two tensors with the same dimensions results in a new tensor with the same dimensions where each scalar value is the element-wise addition of the scalars in the parent tensors.\n",
    "  \n",
    "  A = a(1;1;1) a(1;2;1) a(1;3;1)    a(1;1;2) a(1;2;2) a(1;3;2) \n",
    "      a(2;1;1) a(2;2;1) a(2;3;1) ,  a(2;1;2) a(2;2;2) a(2;3;2)\n",
    "         \n",
    "  B = b(1;1;1) b(1;2;1) b(1;3;1)    b(1;1;2) b(1;2;2) b(1;3;2) \n",
    "      b(2;1;1) b(2;2;1) b(2;3;1) ,  b(2;1;2) b(2;2;2) b(2;3;2)he element-wise subtraction of one tensor from another tensor with the same dimensions\n",
    "results in a new tensor with the same dimensions where each scalar value is the element-wise\n",
    "subtraction of the scalars in the parent tensors.\n",
    "\n",
    "                        C = A+B  \n",
    "                        \n",
    "  C = a(1;1;1)+b(1;1;1) a(1;2;1)+b(1;2;1) a(1;3;1)+b(1;3;1)    a(1;1;2)+b(1;1;2) a(1;2;2)+b(1;2;2) a(1;3;2)+b(1;3;2) \n",
    "      a(2;1;1)+b(2;1;1) a(2;2;1)+b(2;2;1) a(2;3;1)+b(2;3;1) ,  a(2;1;2)+b(2;1;2) a(2;2;2)+b(2;2;2) a(2;3;2)+b(2;3;2) \n",
    "      \n",
    "    13.4.2 Tensor Subtraction\n",
    "   The element-wise subtraction of one tensor from another tensor with the same dimensions results in a new tensor with the same dimensions where each scalar value is the element-wise subtraction of the scalars in the parent tensors.\n",
    "   \n",
    "                       C = A-B        \n",
    "  \n",
    "  C = a(1;1;1)-b(1;1;1) a(1;2;1)-b(1;2;1) a(1;3;1)-b(1;3;1)    a(1;1;2)-b(1;1;2) a(1;2;2)-b(1;2;2) a(1;3;2)-b(1;3;2) \n",
    "      a(2;1;1)-b(2;1;1) a(2;2;1)-b(2;2;1) a(2;3;1)-b(2;3;1) ,  a(2;1;2)-b(2;1;2) a(2;2;2)-b(2;2;2) a(2;3;2)-b(2;3;2)\n",
    "      \n",
    "      \n",
    "    13.4.3 Tensor Hadamard Product\n",
    "  The element-wise multiplication of one tensor with another tensor with the same dimensions results in a new tensor with the same dimensions where each scalar value is the element-wise multiplication of the scalars in the parent tensors. As with matrices, the operation is referred to as the Hadamard Product to di\u000b",
    "erentiate it from tensor multiplication.   \n",
    "  \n",
    "                      C = A*B          \n",
    "                      \n",
    "  C = a(1;1;1)*b(1;1;1) a(1;2;1)*b(1;2;1) a(1;3;1)*b(1;3;1)    a(1;1;2)*b(1;1;2) a(1;2;2)*b(1;2;2) a(1;3;2)*b(1;3;2) \n",
    "      a(2;1;1)*b(2;1;1) a(2;2;1)*b(2;2;1) a(2;3;1)*b(2;3;1) ,  a(2;1;2)*b(2;1;2) a(2;2;2)*b(2;2;2) a(2;3;2)*b(2;3;2)\n",
    "\n",
    "    13.4.4 Tensor Division\n",
    "  The element-wise division of one tensor with another tensor with the same dimensions results in a new tensor with the same dimensions where each scalar value is the element-wise division of the scalars in the parent tensors.  \n",
    "  \n",
    "                      C = A/B\n",
    "                      \n",
    "  C  = a(1;1;1)/b(1;1;1) a(1;2;1)/b(1;2;1) a(1;3;1)/b(1;3;1)    a(1;1;2)/b(1;1;2) a(1;2;2)/b(1;2;2) a(1;3;2)/b(1;3;2) \n",
    "       a(2;1;1)/b(2;1;1) a(2;2;1)/b(2;2;1) a(2;3;1)/b(2;3;1) ,  a(2;1;2)/b(2;1;2) a(2;2;2)/b(2;2;2) a(2;3;2)/b(2;3;2)\n",
    "\n",
    "    13.5 Tensor Product\n",
    "  The tensor product operator is often denoted as a circle with a small x in the middle. tensor A with q dimensions and tensor B with r dimensions, the product of these tensors will be a new tensor with the order of q + r or, said another way, q + r dimensions. The tensor product can be implemented in NumPy using the tensordot() function. The function takes as arguments the two tensors to be multiplied and the axis on which to sum the products over, called the sum reduction. To calculate the tensor product, also called the tensor dot product in NumPy, the axis must be set to 0. \n",
    "  \n",
    "A = a(1;1) a(1;2)     \n",
    "B = b(1;1) b(1;2)    \n",
    "C = A x B = a(1;1) x b(1;1) b(1;2)   a(1;2) x b(1;1) b(1;2)\n",
    "                     b(2;1) b(2;2)            b(2;1) b(2;2)            \n",
    "            a(2;1) x b(1;1) b(1;2)\t a(2;2) x b(1;1) b(1;2)        \n",
    "                     b(2;1) b(2;2)            b(2;1) b(2;2)\n",
    "                     \n",
    "                                                                      \n",
    "C = a(1;1) x b(1;1)   a(1;1) x b(1;2)    a(1;2) x b(1;1)  a(1;2) x b(1;2)\n",
    "    a(1;1) x b(2;1)   a(1;1) x b(2;2)    a(1;2) x b(2;1)  a(1;2) x b(2;2)\n",
    "    a(2;1) x b(1;1)   a(2;1) x b(1;2)\t a(2;2) x b(1;1)  a(2;2) x b(1;2)\n",
    "    a(2;1) x b(2;1)   a(2;1) x b(2;2)\t a(2;2) x b(2;1)  a(2;2) x b(2;2)                                                                                      \n",
    "                        \n",
    "                       \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 5  6]\n",
      "   [ 7  8]]\n",
      "\n",
      "  [[10 12]\n",
      "   [14 16]]]\n",
      "\n",
      "\n",
      " [[[15 18]\n",
      "   [21 24]]\n",
      "\n",
      "  [[20 24]\n",
      "   [28 32]]]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import tensordot\n",
    "\n",
    "A =  array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "\n",
    "B =  array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "\n",
    "#print(A.shape) # prints the shape of the tensor\n",
    "#print(A) #he tensor is printed as a series of matrices, one for each layer i.e. axis 0 specifies the level (like height), axis 1 specifies the column, and axis 2 specifies the row.\n",
    "\n",
    "#print(A+B) # Add two tensors\n",
    "#print(A-B) # subtract two tensors\n",
    "#print(A*B) # multiply two tensors ##tensor Hadamard product\n",
    "#print(A/B) # divide two tensors\n",
    "\n",
    "A =  array([[1,2], [3,4]])\n",
    "B =  array([[5,6], [7,8]])            \n",
    "print(tensordot(A, B, axes = 0)) #axis must be set to 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
