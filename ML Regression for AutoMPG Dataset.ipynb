{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto MPG Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Satish\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Satish\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.936605343993929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Satish\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "############################## Load Libraries #####################################\n",
    "import numpy\n",
    "from pandas import read_csv\n",
    "from numpy import array\n",
    "from numpy import arange\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "############################## Import Dataset #####################################\n",
    "\n",
    "dataset  = read_csv('C:/Users/Satish/python_files/auto.csv')\n",
    "# names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model', 'year', 'origin','car name']\n",
    "############################## Analyse the Data #####################################\n",
    "# print(dataset.head(10))\n",
    "# print(dataset.describe())\n",
    "# print(dataset.shape)\n",
    "# print(dataset.isnull().sum())\n",
    "# print((dataset[['mpg', 'cylinders', 'displacement', 'horsepower', 'weight','acceleration', 'origin']]==0))\n",
    "# print(dataset.columns)\n",
    "# print(dataset.dtypes)\n",
    "\n",
    "############################## Data Visualize #####################################\n",
    "\n",
    "# dataset.hist(sharex=False, sharey=False, xlabelsize=1, ylabelsize=1)\n",
    "# dataset.plot(kind='box', layout=(4,4), subplots=True, sharex=False, fontsize=1)\n",
    "# dataset.plot(kind='density', layout=(4,4), subplots=True, sharex=False, fontsize=1)\n",
    "# scatter_matrix(dataset)\n",
    "# pyplot.show()   \n",
    "### Attribute mpg, accelaration, weight may have bionomial distribution  \n",
    "\n",
    "################### correlation matrix ######################\n",
    "# fig = pyplot.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# cax = ax.matshow(dataset.corr(), vmin=-1, vmax=1, interpolation='none')\n",
    "# fig.colorbar(cax)\n",
    "# ticks = numpy.arange(0,14,1)\n",
    "# ax.set_xticks(ticks)\n",
    "# ax.set_yticks(ticks)\n",
    "# ax.set_xticklabels(names)\n",
    "# ax.set_yticklabels(names)\n",
    "# pyplot.show\n",
    "\n",
    "### Dark yellow region shows positive correclation and dark blue region shows negative correlation\n",
    "### by looking at the matrix we can say that there is heavy positive and negative correlation\n",
    "    \n",
    "############################## Create train and test Dataset #####################################    \n",
    "data = dataset.values\n",
    "# print(data[:10,:])\n",
    "x = data[:,1:8]\n",
    "# print(x[:10,:])\n",
    "y = data[:,0]\n",
    "# print(y[:10])\n",
    "\n",
    "test_size = 0.3\n",
    "num_folds = 10\n",
    "seed = 27\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=test_size, random_state=seed)\n",
    "scoring = 'neg_mean_squared_error'\n",
    "\n",
    "############################## Build the model ###################################################\n",
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('LS', Lasso()))\n",
    "models.append(('EN', ElasticNet()))\n",
    "models.append(('CART', DecisionTreeRegressor()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('SVM', SVR()))\n",
    "\n",
    "############################## Execute the model ###################################################\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "#     print(name, cv_results.mean(), cv_results.std())\n",
    "### LR:-12.62 and LS:-12.87 has lower MSE than others\n",
    "\n",
    "############################## Compare the model ###################################################\n",
    "\n",
    "# fig = pyplot.figure()\n",
    "# fig.suptitle('Algorithm Comparison')\n",
    "# ax = fig.add_subplot(111)\n",
    "# pyplot.boxplot(results)\n",
    "# ax.set_xticklabels(names)\n",
    "# pyplot.show()\n",
    "# ### From above plot we can say that LR and LS show lower MSE than others\n",
    "\n",
    "############################## Standardize the dataset and Build the model #############################\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()), ('LR', LinearRegression())])))\n",
    "pipelines.append(('ScaledLS', Pipeline([('Scaler', StandardScaler()), ('LS', Lasso())])))\n",
    "pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()), ('EN', ElasticNet())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()), ('CART', DecisionTreeRegressor())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()), ('KNN', KNeighborsRegressor())])))\n",
    "pipelines.append(('ScaledSVM', Pipeline([('Scaler', StandardScaler()), ('SVM', SVR())])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "# for name, model in pipelines:\n",
    "#     kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "#     cv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "#     results.append(cv_results)\n",
    "#     names.append(name)\n",
    "#     print(name, cv_results.mean(), cv_results.std())\n",
    "### SCaling has show its effect on KNN(-10.92) by bringing down the error\n",
    "\n",
    "############################## Compare the Scaled model ####################################### \n",
    "\n",
    "# fig = pyplot.figure()\n",
    "# fig.suptitle('Scaled Algorothm Comparison')\n",
    "# ax = fig.add_subplot(111)\n",
    "# pyplot.boxplot(results)\n",
    "# ax.set_xticklabels(names)\n",
    "# pyplot.show()\n",
    "### KNN  has lowest MSE than others\n",
    "\n",
    "############################## Improve result with Tuning #######################################\n",
    "scaler = StandardScaler().fit(x_train)\n",
    "rescaledx = scaler.transform(x_train)\n",
    "# k_values = numpy.array([1,3,5,7,9,11,13,15,17,19,21])\n",
    "param_grid = dict(n_neighbors = k_values)\n",
    "model = KNeighborsRegressor()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid  = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold, scoring=scoring)\n",
    "grid_results = grid.fit(rescaledx, y_train)\n",
    "# print(\"Best Score: \", grid_results.best_score_, \"Best param: \", grid_results.best_params_)\n",
    "mean = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "# for mean, std, param in zip(mean, stds, params):\n",
    "#     print(mean, std, param)\n",
    "#### Tunning has improves KNN (-10.32) score slightly   \n",
    "\n",
    "############################## Improve the performanc using ensemble methods #############################\n",
    "ensembles = []\n",
    "ensembles.append(('ScaledAB', Pipeline([('Scaler', StandardScaler()), ('AB', AdaBoostRegressor())])))\n",
    "ensembles.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()), ('GBM', GradientBoostingRegressor())])))\n",
    "ensembles.append(('ScaledRM', Pipeline([('Scaler', StandardScaler()), ('RM', RandomForestRegressor())])))\n",
    "ensembles.append(('ScaledET', Pipeline([('Scaler', StandardScaler()), ('ET', ExtraTreesRegressor())])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "# for name, model in ensembles:\n",
    "#     kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "#     cv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "#     results.append(cv_results)\n",
    "#     names.append(name)\n",
    "#     print(name, cv_results.mean(), cv_results.std())\n",
    "### Gradient Boosting has improve the performance (-9.68)\n",
    "\n",
    "\n",
    "# fig = pyplot.figure()\n",
    "# fig.suptitle('Scaled Ensemble Algorithm Comparison')\n",
    "# ax = fig.add_subplot(111)\n",
    "# pyplot.boxplot(results)\n",
    "# ax.set_xticklabels(names)\n",
    "# pyplot.show() \n",
    "### It looks like Gradient Boosting has a better mean score.\n",
    "\n",
    "############################## Tune Ensemble Mothods #######################################\n",
    "\n",
    "scaler = StandardScaler().fit(x_train)\n",
    "rescaledx = scaler.transform(x_train)\n",
    "param_grid = dict(n_estimators = numpy.array([50,100, 150, 200, 250, 300, 350, 400]))\n",
    "model = GradientBoostingRegressor(random_state=seed)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold, scoring=scoring)\n",
    "grid_result = grid.fit(rescaledx, y_train)\n",
    "# print(\"Best Scor: \", grid_result.best_score_, \"Using param: \", grid_result.best_params_)\n",
    "mean = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# for mean, std, param in zip(mean, stds, params):\n",
    "#     print(mean, std, param)\n",
    "#### Tunning has slightly improves GB ensemble methods score (-9.53) using n_estimators = 100\n",
    "\n",
    "############################## Finalize the model #######################################\n",
    "\n",
    "scaler = StandardScaler().fit(x_train)\n",
    "rescaledx = scaler.transform(x_train)\n",
    "model = GradientBoostingRegressor(n_estimators=100, random_state=seed)\n",
    "model.fit(rescaledx, y_train)\n",
    "\n",
    "resclaledtest_x = scaler.transform(x_test)\n",
    "prediction = model.predict(resclaledtest_x)\n",
    "print(mean_squared_error(y_test, prediction))\n",
    "\n",
    "######### mean_squared_error : 5.93"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
